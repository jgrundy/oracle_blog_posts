{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/funcy/colls.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable, Iterator, defaultdict\n",
      "/usr/local/lib/python3.7/site-packages/funcy/colls.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable, Iterator, defaultdict\n",
      "/usr/local/lib/python3.7/site-packages/funcy/seqs.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import defaultdict, deque, Sequence\n",
      "/usr/local/lib/python3.7/site-packages/funcy/flow.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Hashable\n",
      "/usr/local/lib/python3.7/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n",
      "/usr/local/lib/python3.7/site-packages/nltk/decorators.py:70: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  formatvalue=lambda value: \"\")[1:-1]\n"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import gensim as gs\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "from collections import OrderedDict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessor(dataframe, text_column):\n",
    "    \"\"\"Takes in a Pandas dataframe column or Series of texts and preprocesses them for model building.\"\"\"\n",
    "    #set up the NLP variables needed for preprocessing\n",
    "    stop = list(stopwords.words('english'))\n",
    "    stop.extend(['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])\n",
    "\n",
    "    punctuation = list(string.punctuation)\n",
    "    punctuation.extend(['1','2','3','4','5','6','7','8','9','0'])\n",
    "\n",
    "    letters = list(string.ascii_lowercase)\n",
    "    \n",
    "    #remove the line breaks from each of the reviews\n",
    "    dataframe[text_column] = dataframe[text_column].apply(lambda x: ' '.join(x.splitlines()))\n",
    "    \n",
    "    #remove punctuation\n",
    "    dataframe[text_column] = dataframe[text_column].apply(lambda x: ''.join(char for char in x if char not in punctuation))\n",
    "\n",
    "    #tokenize the documents\n",
    "    dataframe[text_column] = dataframe[text_column].apply(lambda x: word_tokenize(x.lower()))\n",
    "    \n",
    "    #remove stopwords\n",
    "    dataframe[text_column] = dataframe[text_column].apply(lambda x: [i for i in x if i not in stop])\n",
    "\n",
    "    #lemmatize the results\n",
    "    dataframe[text_column] = dataframe[text_column].apply(lambda x: [WordNetLemmatizer().lemmatize(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create dictionary to show outputs of each topic on a bar graph\n",
    "def graph_topics(model, corpus, documents, num_topics,normalize=False, num_words=5, figsize=(8,8)):\n",
    "    \"\"\"Visualizes the top represented topics in the corpus.\"\"\"\n",
    "    topic_counter = {}\n",
    "    joined = {}\n",
    "    \n",
    "    topics, top_words = get_top_terms(model, num_topics=num_topics)\n",
    "    for i in range(len(topics)):\n",
    "        a = {topics[i]: str(top_words[i])}\n",
    "        joined.update(a)\n",
    "\n",
    "    #topic distribution by document\n",
    "    for i in range(len(documents)):\n",
    "        for topic, percent in model.get_document_topics(corpus)[i]:\n",
    "            topic_key = \"Topic %s\" % topic\n",
    "            topic_counter[topic_key]  = topic_counter.get(topic_key, 0) + 1\n",
    "    \n",
    "    #remap the keys to the topn words from each topic\n",
    "    topic_counter = dict((joined[key], value) for (key, value) in topic_counter.items())\n",
    "    \n",
    "    #choose whether to display by count in # of documents or by % of corpus\n",
    "    if normalize == True:\n",
    "        for k, v in topic_counter.items():\n",
    "            topic_counter[k] = topic_counter[k] / float(len(documents))\n",
    "    \n",
    "    #sort the dictionary for better output\n",
    "    topic_counter = OrderedDict(sorted(topic_counter.items(), key=lambda x: x[1]))\n",
    "    \n",
    "    #visualize the results\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.barh(range(len(topic_counter)), list(topic_counter.values()), align='center')\n",
    "    plt.yticks(range(len(topic_counter)), list(topic_counter.keys()))\n",
    "    plt.xlabel('Topic Representation in Total Documents')\n",
    "    plt.ylabel('TopN Words from Each Topic')\n",
    "    plt.title('Topics in Documents')\n",
    "    plt.grid(axis='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_terms(model, num_topics, num_words=5):\n",
    "    \"\"\"Takes in the .show_topics() method and creates a list of top 5 words for each topic and a list of topics\"\"\"\n",
    "    topics = []\n",
    "    topic_words = []\n",
    "\n",
    "    for i in model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False):\n",
    "        topics.append('Topic %s' % i[0])\n",
    "        temp = []\n",
    "\n",
    "        for j in i[1]:\n",
    "            temp.append(j[0].encode('utf-8'))\n",
    "        topic_words.append(str(temp).translate(None, \"[']\"))\n",
    "\n",
    "    return topics, topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_best_model(dictionary, corpus, texts, start=1, stop=21, increment=2, passes=5, \n",
    "                           iterations=5, workers=3, visualize=True):\n",
    "    \"\"\"Computes model coherence for a variety of LDA models and returns the model with highest coherence.\n",
    "    also has optional visualization\"\"\"\n",
    "    model_list = []\n",
    "    coherence_list = []\n",
    "    \n",
    "    #compute the models\n",
    "    for i in range(start, stop, increment):\n",
    "        model = models.ldamulticore.LdaMulticore(corpus, id2word=dictionary, num_topics=i, \n",
    "                                                 passes=passes, iterations=iterations, workers=workers)\n",
    "        coherence = models.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        model_list.append(model)\n",
    "        coherence_list.append(coherence.get_coherence())\n",
    "    \n",
    "    #find the best model from the computed models\n",
    "    best_model = model_list[coherence_list.index(max(coherence_list))]\n",
    "    \n",
    "    #optional visualization of all topics\n",
    "    if visualize == True:\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.plot(range(start, stop, increment), coherence_list, color='r')\n",
    "        plt.xlabel('Number of Topics')\n",
    "        plt.ylabel('Coherence Value')\n",
    "        plt.grid()\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://raw.githubusercontent.com/justmarkham/DAT7/master/data/yelp.csv\n",
    "data = pd.read_csv('yelp.csv')\n",
    "\n",
    "#useful for a later time, but not for now\n",
    "# #find all the restaurants that have at least 10 reviews\n",
    "# restaurants = data.groupby('business_id').count().sort_values('stars', ascending=False)\n",
    "# restaurants = restaurants[restaurants.stars >= 10]\n",
    "\n",
    "# #filter the main dataset for restaurants that have at least 10 reviews each\n",
    "# filtered = data[data['business_id'].isin(restaurants.index)]\n",
    "# filtered.head(2)\n",
    "\n",
    "text_preprocessor(data, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build a total dictionary of all words in all documents\n",
    "dictionary = corpora.Dictionary(data.text)\n",
    "\n",
    "#build a per-document numerical representation of the dataset\n",
    "corpus = [dictionary.doc2bow(doc) for doc in data.text]\n",
    "\n",
    "#build and train the LDA model\n",
    "ldamodel = models.ldamulticore.LdaMulticore(corpus, id2word=dictionary, \n",
    "                                            num_topics=20, passes=10, iterations=20,\n",
    "                                            workers=3)\n",
    "\n",
    "dictionary.num_pos\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the top terms for each topic. this is something easily seen in pyLDAvis\n",
    "for i in range(5):\n",
    "    print(\"Topic #: \", i)\n",
    "    print(ldamodel.get_topic_terms(i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.show_topics(num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.top_topics(corpus=bow, dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_topics(model=ldamodel, corpus=corpus, documents=data.text, num_topics=50, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = compute_best_model(dictionary=dictionary, corpus=corpus, texts=data.text, start=5, stop=70, \n",
    "                              increment=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = models.ldamulticore.LdaMulticore(bow, id2word=dictionary, num_topics=10, passes=10, iterations=10, workers=3)\n",
    "\n",
    "pyLDAvis.gensim.prepare(ldamodel, bow, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(ldamodel.get_document_topics(corpus)[i])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel.print_topics(3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regex to revisit later\n",
    "\n",
    "#     dataframe[text_column].replace(\"[!@#$'%^:;,\"\"&*)(-+.{|}[\\]=<>?/\\\\\\~`]\", ' ', regex=True, inplace=True)\n",
    "#     dataframe[text_column].replace('[!\"#%\\'()*+,-./:;<=>?@\\[\\]^_`{|}~1234567890’”“′‘\\\\\\]', ' ', regex=True, inplace=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
